import webrtcvad
import collections
import numpy as np


# ì‹¤ì‹œê°„ ìŒì„± ê°ì§€ ë° ë…¹ìŒì„ ìœ„í•œ í´ë˜ìŠ¤
class VoiceActivityDetector:
    # VoiceActivityDetector ìƒì„±ì ì´ˆê¸°í™”
    def __init__(self, sample_rate=16000, frame_duration_ms=30, silence_threshold=33, volume_threshold=0.7):
        # ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (Hz) - ì¼ë°˜ì ìœ¼ë¡œ 16kHz ì‚¬ìš©
        self.sample_rate = sample_rate
        # 1 í”„ë ˆì„ ê¸¸ì´ (ms ë‹¨ìœ„) - 30msê°€ ì¼ë°˜ì 
        self.frame_duration_ms = frame_duration_ms
        # í”„ë ˆì„ ë‹¹ ìƒ˜í”Œ ìˆ˜ = ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ X í”„ë ˆì„ ì§€ì†ì‹œê°„ / 1000
        self.frame_size = int(sample_rate * frame_duration_ms / 1000)
        # ë¬´ìŒì´ ê°ì§€ë  ìˆ˜ ìˆëŠ” ìµœëŒ€ í”„ë ˆì„ ìˆ˜ (30ms x 33 = ì•½ 1ì´ˆ)
        self.silence_threshold = silence_threshold
        # ìŒì„± ìµœì†Œ ë³¼ë¥¨ ê°ì§€ ì„ê³„ê°’ (0.7 ì´ìƒì´ë©´ ìŒì„±ìœ¼ë¡œ ê°„ì£¼)
        self.volume_threshold = volume_threshold

        # ìŒì„± ê°ì§€ ê°ì²´ ìƒì„± (3ì€ ë¯¼ê°ë„ ì„¤ì •)
        self.vad = webrtcvad.Vad(3)
        # reset ë©”ì„œë“œ í˜¸ì¶œ (ë‚´ë¶€ ìƒíƒœ ì´ˆê¸°í™”)
        self.reset()

    # ë‚´ë¶€ ìƒíƒœ ì´ˆê¸°í™” ë©”ì„œë“œ
    def reset(self):
        # í˜„ì¬ ìŒì„± ë…¹ìŒ ì¤‘ì¸ì§€ ì—¬ë¶€
        self.triggered = False
        # ë¬´ìŒì´ ê°ì§€ëœ í”„ë ˆì„ ìˆ˜
        self.silence_count = 0
        # ìµœê·¼ ë¬´ìŒ í”„ë ˆì„ì„ ë²„í¼ì— ì €ì¥
        self.ring_buffer = collections.deque(maxlen=self.silence_threshold)
        # ì „ì²´ ë…¹ìŒëœ ì˜¤ë””ì˜¤ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
        self.recording = []

    # WebRTC VADë¡œ ìŒì„± ì—¬ë¶€ íŒë‹¨
    def is_speech(self, pcm):
        # float PCM -> init16 PCM -> ë°”ì´íŠ¸ë¡œ ë³€í™˜
        pcm_bytes = (pcm * 32768).astype(np.int16).tobytes()
        # WebRTC VADì— ë°”ì´íŠ¸ ì˜¤ë””ì˜¤ ì „ë‹¬í•˜ì—¬ ìŒì„± ì—¬ë¶€ ë°˜í™˜
        return self.vad.is_speech(pcm_bytes, self.sample_rate)

    # PCM ë°ì´í„°ë¥¼ ë°›ì•„ ìŒì„± ì—¬ë¶€ íŒë‹¨ ë° ë…¹ìŒ ì²˜ë¦¬
    def process_audio(self, pcm):
        """
        ì‹¤ì‹œê°„ìœ¼ë¡œ PCM ë°ì´í„°ë¥¼ ë°›ì•„ ìŒì„±ì„ ê°ì§€í•˜ê³ ,
        ë¬´ìŒ 1ì´ˆ ì§€ì† ì‹œ ë…¹ìŒì„ ì¢…ë£Œí•˜ê³  ìµœì¢… ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°˜í™˜í•œë‹¤.

        :param pcm: float32 PCM (normalized -1.0 ~ 1.0)
        :return: ë…¹ìŒ ì¢…ë£Œ ì‹œ np.ndarray ë°˜í™˜, ê³„ì† ë…¹ìŒ ì¤‘ì´ë©´ None
        """
        samples_per_frame = self.frame_size
        # ì´ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        num_frames = len(pcm) // samples_per_frame

        # ì…ë ¥ëœ PCM í”„ë ˆì„ì„ êµ¬ì„±í•  ë§Œí¼ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ì²˜ë¦¬í•˜ì§€ ì•ŠëŠ”ë‹¤
        if num_frames == 0:
            return None

        # PCM ë°ì´í„°ë¥¼ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for i in range(num_frames):
            frame = pcm[i * samples_per_frame:(i + 1) * samples_per_frame]

            # ë³¼ë¥¨ ê³„ì‚° (ì ˆëŒ“ê°’ ì¤‘ ìµœëŒ€ê°’)
            volume = np.max(np.abs(frame))
            if volume < self.volume_threshold:
                speech = False
            else:
                # WebRTC VADë¡œ ì‹¤ì œ ìŒì„± ì—¬ë¶€ íŒë‹¨
                speech = self.is_speech(frame)

            print(f"{'ğŸ™ï¸ ê°ì§€ë¨' if speech else 'ğŸ”ˆ ë¬´ìŒ'} | volume={volume:.4f}")

            # ìŒì„±ì´ ê°ì§€ë˜ë©´ ë…¹ìŒ ìƒíƒœë¡œ ì „í™˜
            if self.triggered:
                # í”„ë ˆì„ ì €ì¥
                self.recording.append(frame)
                if not speech:
                    # ë¬´ìŒ ì¹´ìš´íŠ¸ ì¦ê°€
                    self.silence_count += 1
                    # ì¼ì • ì‹œê°„ ì´ìƒ ë¬´ìŒì´ë©´ ë…¹ìŒ ì¢…ë£Œ (ì•½ 1ì´ˆ)
                    if self.silence_count > self.silence_threshold:
                        audio_data = np.concatenate(self.recording)
                        self.reset()
                        return audio_data
                else:
                    # ìŒì„± ê°ì§€ ì‹œ ë¬´ìŒ ì¹´ìš´í„° ì´ˆê¸°í™”
                    self.silence_count = 0
            # ì•„ì§ ë…¹ìŒì„ ì‹œì‘í•˜ì§€ ì•Šì€ ê²½ìš°
            else:
                # ìµœê·¼ í”„ë ˆì„ì„ ë§ë²„í¼ì— ì €ì¥
                self.ring_buffer.append(frame)
                if speech and volume > self.volume_threshold:
                    print("ğŸ¤ ìŒì„± ì‹œì‘ â†’ ë…¹ìŒ ì‹œì‘")
                    # ë…¹ìŒ ì‹œì‘
                    self.triggered = True
                    # ì‹œì‘ ì „ ë¬´ìŒë„ í¬í•¨
                    self.recording.extend(self.ring_buffer)
                    # ë²„í¼ ì´ˆê¸°í™”
                    self.ring_buffer.clear()

        return None # ë…¹ìŒ ì¢…ë£Œ ì¡°ê±´ì„ ì•„ì§ ì¶©ì¡±í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
